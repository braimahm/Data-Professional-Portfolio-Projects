####This block of code is only necessary if you are using COLAB

#from google.colab import drive
#drive.mount('/content/gdrive', force_remount=True)
#from google.colab import output 
#output.enable_custom_widget_manager()
#def changeDirectory(path):
#  original_path=os.getcwd()
#  os.chdir(path)
#  new_path=os.getcwd()
#  print("Original path: ",original_path)
#  print("New path: ",new_path)

##  The new folder must be created prior to running the next step
##  in my example I created a folder named _WorkingData

#changeDirectory("/content/gdrive/MyDrive/_WorkingData/")
#---------------------------------------------------------------
## This step imports the packages used throughout the following code
## if you run individual blocks it will be necessary to paste this each time
## however not all packages are used for individual steps of processing

import pandas as pd
import numpy as np
import autograd.numpy
from autograd import grad
from array import array
import matplotlib.pyplot as plt
from matplotlib import figure
import seaborn as sns
import glob
import numexpr as ne 
import re
import datetime
import scipy.interpolate
import scipy.stats as stats
from scipy.stats import f_oneway
import statsmodels.api as sm
from statsmodels.formula.api import ols
from sklearn.decomposition import FactorAnalysis, PCA
from sklearn.preprocessing import StandardScaler
import ipywidgets as widgets
from ipywidgets import interact, interactive
from IPython.display import display, HTML

## This is a Windows specific callout used to link the IBM statistics program
## SPSS as well as increase the number of threads used to process data when
## utilizing machine power (i.e. you won't need this block when using COLAB)

#import sys
#sys.path.insert(0,r"C:\Program Files\IBM\SPSS Statistics\Python3\Lib\site-packages")
#import spss, SpssClient
#import os
#os.environ['NUMEXPR_MAX_THREADS'] = '10'
#os.environ['NUMEXPR_NUM_THREADS'] = '8'

## This is a display preference command line for Jupyter specific plotting
## not needed for COLAB

#%matplotlib notebook
#%matplotlib inline

#----------------------------------------------------------------------------------------------------
#----------------------------------------------------------------------------------------------------
# This block begins the actual data processing step
#----------------------------------------------------------------------------------------------------

## Machine Drift Correction

spectra = pd.read_csv("E:/PhD_Research/_Working_Data/All_1nm_Lab Data_01Oct.csv", index_col= "ID")
print(spectra)

# With such a large dataset, we use the column loc function to make sure we are selecting the proper 
# column labels to use for the correction factor

spectra.columns.get_loc('1000')
spectra.iloc[:,650:]

# Once we are satisfied we have the correct column labels, we then make a clip of the isolated dataset
# to perform the correction

spectraclip = spectra.iloc[:,650:]
print(spectraclip)

# Create a DF from that clip

df2 = pd.DataFrame(spectraclip)
df2.to_csv("E:/PhD_Research/_Working_Data/spectraclip.csv")

# Next we will calculate the correction factor needed to apply to the clipped data

CorrectionF = (spectra['650']/spectra['651'])
print(CorrectionF)

# 